{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9999c05a",
   "metadata": {},
   "source": [
    "## Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5724fc75",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import pyrtools as pt\n",
    "from scipy import signal\n",
    "from scipy import ndimage\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9f20931",
   "metadata": {},
   "source": [
    "## Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c42e0a46",
   "metadata": {},
   "outputs": [],
   "source": [
    "def RGB2Lab(im):\n",
    "    im = np.float32(im)/255\n",
    "\n",
    "    mask = im >= 0.04045\n",
    "    im[mask] = ((im[mask] + 0.055) / 1.055)**2.4\n",
    "    im[~mask] = im[~mask] / 12.92\n",
    "\n",
    "    \n",
    "    matrix = np.array([[0.412453, 0.357580, 0.180423],\n",
    "          [0.212671, 0.715160, 0.072169],\n",
    "          [0.019334, 0.119193, 0.950227]])\n",
    "\n",
    "    \n",
    "    c_im = np.dot(im, matrix.T)\n",
    "    c_im[:,:,0] = c_im[:,:,0] / 95.047\n",
    "    c_im[:,:,1] = c_im[:,:,1] / 100.000\n",
    "    c_im[:,:,2] = c_im[:,:,2] / 108.833\n",
    "\n",
    "\n",
    "    mask = c_im >= 0.008856\n",
    "    c_im[mask] = c_im[mask] ** (1/3)\n",
    "    c_im[~mask] = 7.787 * c_im[~mask] + 16/116\n",
    "\n",
    "    im_Lab = np.zeros_like(c_im)\n",
    "\n",
    "    im_Lab[:,:,0] = ( 116 * c_im[:,:,1] ) - 16\n",
    "    im_Lab[:,:,1] = 500 * ( c_im[:,:,0] - c_im[:,:,1] )\n",
    "    im_Lab[:,:,2] = 200 * ( c_im[:,:,1] - c_im[:,:,2] )\n",
    "\n",
    "    \n",
    "    return im_Lab\n",
    "    \n",
    "    \n",
    "def normlize(arr):\n",
    "    return ((arr - arr.min()) * (1/(arr.max() - arr.min()) * 255)).astype('uint8')\n",
    "\n",
    "def conv2(x, y, mode=None):\n",
    "    \n",
    "    if mode == 'same':\n",
    "        return np.rot90(signal.convolve2d(np.rot90(x, 2), np.rot90(y, 2), mode=mode), 2)\n",
    "    else:\n",
    "        return signal.convolve2d(x, y)\n",
    "        \n",
    "\n",
    "def RRoverlapconv(kernel, in_):\n",
    "    out = conv2(in_, kernel, mode='same')\n",
    "    rect = np.ones_like(in_)\n",
    "\n",
    "    overlapsum = conv2(rect, kernel, 'same')\n",
    "    out = np.sum(kernel) * out / overlapsum\n",
    "    return out\n",
    "\n",
    "\n",
    "def RRgaussfilter1D(halfsupport, sigma, center=0):\n",
    "    t = list(range(-halfsupport, halfsupport+1))\n",
    "    kernel = np.array([np.exp(-(x-center) **2 /(2* sigma ** 2)) for x in t])\n",
    "    kernel = kernel/sum(kernel)\n",
    "    \n",
    "    return kernel.reshape(1,kernel.shape[0])\n",
    "\n",
    "\n",
    "\n",
    "def DoG1filter(a,sigma):\n",
    "    \n",
    "    sigi = 0.71 * sigma\n",
    "    sigo = 1.14 * sigma\n",
    "    \n",
    "    t = range(-a, a+1)\n",
    "    \n",
    "    gi = [np.exp(-x ** 2 /(2 * sigi ** 2)) for x in t]\n",
    "    gi = gi/sum(gi)\n",
    "    go = [np.exp(- x ** 2/(2 * sigo ** 2)) for x in t]\n",
    "    go = go/sum(go)\n",
    "    \n",
    "    return gi.reshape(1,gi.shape[0]),go.reshape(1,go.shape[0])\n",
    "\n",
    "\n",
    "def addborder(im,xbdr,ybdr,arg):\n",
    "    \"\"\"\n",
    "    imnew = addborder(im,xborder,yborder,arg)  Make image w/added border.\n",
    "    imnew = addborder(im,5,5,128)  Add 5 wide border of val 128.\n",
    "    imnew = addborder (im,5,5,'even')  Even reflection.\n",
    "    imnew = addborder (im,5,5,'odd')  Odd reflection.\n",
    "    imnew = addborder (im,5,5,'wrap')  Wraparound.\n",
    "    \"\"\"\n",
    "    ysize, xsize = im.shape\n",
    "    \n",
    "    \n",
    "#     check thickness\n",
    "    if (xbdr > xsize) or (ybdr > ysize):\n",
    "        raise ValueError('borders must be thinner than image')\n",
    "    \n",
    "#     if arg is a number, fill border with its value.\n",
    "    if isinstance(arg, (int, float)):\n",
    "        imbig = cv2.copyMakeBorder(im, ybdr,ybdr,xbdr,xbdr, cv2.BORDER_CONSTANT, value=arg)\n",
    "    \n",
    "#     Even reflections\n",
    "    elif arg == 'even':\n",
    "        imbig = cv2.copyMakeBorder(im, ybdr,ybdr,xbdr,xbdr, cv2.BORDER_REFLECT)\n",
    "        \n",
    "#     Odd reflections\n",
    "    elif arg == 'odd':\n",
    "        imbig = cv2.copyMakeBorder(im, ybdr,ybdr,xbdr,xbdr, cv2.BORDER_REFLECT_101)\n",
    "        \n",
    "#    Wraparound\n",
    "    elif arg == 'wrap':\n",
    "        imbig = cv2.copyMakeBorder(im, ybdr,ybdr,xbdr,xbdr, cv2.BORDER_WRAP)\n",
    "    else:\n",
    "        raise ValueError('unknown border style')\n",
    "    return imbig\n",
    "\n",
    "\n",
    "def filt2(kernel, im1, reflect_style='odd'):\n",
    "    \"\"\"\n",
    "    im2 = filt2(kernel,im1,reflect_style)\n",
    "    Improved version of filter2 in MATLAB, which includes reflection.\n",
    "    Default style is 'odd'. Also can be 'even', or 'wrap'.\n",
    "    im2 = filt2(kern,image)  apply kernel with odd reflection (default).\n",
    "    im2 = filt2(kern,image,'even')  Use even reflection.\n",
    "    im2 = filt2(kern,image,128)  Fill with 128's.\n",
    "\n",
    "    Ruth Rosenholtz\n",
    "    \"\"\"\n",
    "    \n",
    "    ky,kx = kernel.shape\n",
    "    iy,ix = im1.shape\n",
    "\n",
    "    # TODO: index should be checked, maybe it needs to be changed 1 pixel (getting back -1)\n",
    "    imbig = addborder(im1, kx, ky, reflect_style)\n",
    "    imbig = conv2(imbig, kernel, 'same')\n",
    "    im2 = imbig[ky:ky+iy, kx:kx+ix]\n",
    "\n",
    "\n",
    "    return im2\n",
    "\n",
    "\n",
    "def RRcontrast1channel(pyr, DoG_sigma=2):\n",
    "    \n",
    "    levels = len(pyr)\n",
    "    contrast = [0] * levels\n",
    "    \n",
    "    innerG1, outerG1 = DoG1filter(round(DoG_sigma*3), DoG_sigma)\n",
    "\n",
    "\n",
    "    for i in range(0,levels):\n",
    "        inner = filt2(innerG1, pyr[(i,0)])\n",
    "        inner = filt2(innerG1.T, inner)\n",
    "        outer = filt2(outerG1, pyr[(i,0)])\n",
    "        outer = filt2(outerG1.T, outer)\n",
    "        tmp = inner - outer\n",
    "        contrast[i] = abs(tmp)\n",
    " \n",
    "    return contrast\n",
    "\n",
    "\n",
    "def reduce(image0, kernel=None):\n",
    "    \"\"\"\n",
    "    Reduce: for building Gaussian or Laplacian pyramids. 1-D separable kernels.\n",
    "\n",
    "    imnew = reduce(im0) Reduce w/default kernel: [.05 .25 .4 .25 .05]\n",
    "    imnew = reduce(im0, kern) Reduce with kern; sums to unity.\n",
    "\n",
    "    Ruth Rosenholtz \n",
    "    \"\"\"\n",
    "\n",
    "    \n",
    "    if kernel is None:\n",
    "    #     Default kernel \n",
    "        kernel = np.array([[0.05, 0.25, 0.4, 0.25, 0.05]])\n",
    "\n",
    "\n",
    "    ysize, xsize = image0.shape\n",
    "\n",
    "    image0 = filt2(kernel,image0) # Filter horizontally. \n",
    "#     filt2 is filter2 with reflection.\n",
    "    image1 = image0[:,range(0,xsize,2)]\n",
    "\n",
    "    image1 = filt2(kernel.T,image1) # Filter vertically.\n",
    "    image2 = image1[range(0,ysize,2),:]\n",
    "\n",
    "    return image2\n",
    "\n",
    "\n",
    "def RRoverlapconvexpand(in_, kernel=None):\n",
    "    \"\"\"\n",
    "    out = RRoverlapconvexpand(in_)  return an image expanded to double size,\n",
    "    out = RRoverlapconvexpand(in, kernel); specify 1-D kernel with unity sum.\n",
    "    \"\"\"\n",
    "    \n",
    "    if kernel is None:\n",
    "    #     Default kernel \n",
    "        kernel = np.array([[0.05, 0.25, 0.4, 0.25, 0.05]])\n",
    "\n",
    "    ysize, xsize = in_.shape\n",
    "    kernel = kernel * 2 # kernel sum=2 to account for padding.\n",
    "\n",
    "    tmp = np.zeros([ysize,2*xsize]) # First double the width\n",
    "    k = list(range(0, xsize))\n",
    "    k_2 = [x*2 for x in k]\n",
    "    tmp[:,k_2] = in_[:,k]\n",
    "    tmp = RRoverlapconv(kernel,tmp) # ..and filter horizontally. \n",
    "\n",
    "    out = np.zeros([2*ysize,2*xsize]) # Next double the height\n",
    "    k = list(range(0, ysize))\n",
    "    k_2 = [x*2 for x in k]\n",
    "    out[k_2,:] = tmp[k,:]\n",
    "    out = RRoverlapconv(kernel.T,out) # ..and filter vertically.\n",
    "\n",
    "    return out\n",
    "\n",
    "\n",
    "def HV(in_):\n",
    "    out = in_[0] - in_[1]\n",
    "    return out\n",
    "\n",
    "\n",
    "def DD(in_):\n",
    "    out = in_[3] - in_[2]\n",
    "    return out\n",
    "\n",
    "\n",
    "def sumorients(in_):\n",
    "    out =  in_[0] + in_[1] + in_[2] + in_[3]\n",
    "    return out\n",
    "\n",
    "\n",
    "\n",
    "def poolnew(in_, sigma=None):\n",
    "    \"\"\"\n",
    "    Pools with a gaussian.  Note assumes that input image is actually\n",
    "    4 equal-size images, side by side.\n",
    "\n",
    "    Usage: out = poolnew(input_image, sigma)\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    in1 = in_[0] #H -> first quarter\n",
    "    in2 = in_[1] #V -> second quarter\n",
    "    in3 = in_[2] #L -> third quarter\n",
    "    in4 = in_[3] #R -> last quarter\n",
    "\n",
    "    \n",
    "    if sigma is None:\n",
    "        out1 = reduce(RRoverlapconvexpand(in1))\n",
    "        out2 = reduce(RRoverlapconvexpand(in2))\n",
    "        out3 = reduce(RRoverlapconvexpand(in3))\n",
    "        out4 = reduce(RRoverlapconvexpand(in4))\n",
    "    else:\n",
    "        kernel = RRgaussfilter1D(round(2*sigma), sigma)\n",
    "        out1 = reduce(RRoverlapconvexpand(in1, kernel), kernel)\n",
    "        out2 = reduce(RRoverlapconvexpand(in2, kernel), kernel)\n",
    "        out3 = reduce(RRoverlapconvexpand(in3, kernel), kernel)\n",
    "        out4 = reduce(RRoverlapconvexpand(in4, kernel), kernel)    \n",
    "\n",
    "    out = out1, out2, out3, out4\n",
    "\n",
    "    return out\n",
    "\n",
    "\n",
    "def imrotate(im, angle, method='nearest', bbox='crop'):\n",
    "    func_method = {'nearest':0,'bilinear':2,'bicubic':3,'cubic':3}\n",
    "    func_bbox = {'loose':True,'crop':False}\n",
    "    PIL_im = Image.fromarray(im)\n",
    "\n",
    "    im_rot = PIL_im.rotate(angle, expand = func_bbox[bbox], resample = func_method[method])\n",
    "    return np.array(im_rot)\n",
    "\n",
    "def imrotate2(im, angle, method='cubic', bbox='crop'):\n",
    "#     By default rotate uses cubic interpolation\n",
    "    return ndimage.rotate(im, angle=angle)\n",
    "\n",
    "\n",
    "def orient_filtnew(pyr, sigma=16/14):\n",
    "    \"\"\"\n",
    "    ORIENT_FILTNEW Filters \"pyr\" (in principle, one level of the\n",
    "        Gaussian pyramid generated by gausspyr) with 2nd\n",
    "        derivative filters in 4 directions\n",
    "\n",
    "    Usage: hvdd = orient_filt(pyr)\n",
    "        Where hvdd is the 4 output images concatenated \n",
    "        together, in the order horizontal, vertical, up-left,\n",
    "        and down-right.\n",
    "    \"\"\"\n",
    "    \n",
    "\n",
    "    halfsupport = round(3*sigma)   \n",
    "#     halfsupport was 10, for default sigma.  We need a halfsupport of about\n",
    "#     2*sigma for a single Gaussian.  Here we have three, one at -sigma, one at\n",
    "#     sigma, so we should need a halfsupport of about 3*sigma.\n",
    "\n",
    "\n",
    "    sigy = sigma\n",
    "    sigx = sigma # Was sigx = 3*sigma.\n",
    "\n",
    "    gx = RRgaussfilter1D(halfsupport, sigx)\n",
    "    gy = RRgaussfilter1D(halfsupport, sigy, sigma)\n",
    "    Ga = conv2(gx, gy.T)\n",
    "    Ga = Ga/sum(sum(Ga))\n",
    "    gy = RRgaussfilter1D(halfsupport, sigy)\n",
    "    Gb = conv2(gx, gy.T)\n",
    "    Gb = Gb/sum(sum(Gb))\n",
    "    gy = RRgaussfilter1D(halfsupport, sigy, -sigma)\n",
    "    Gc = conv2(gx, gy.T)\n",
    "    Gc = Gc/sum(sum(Gc))\n",
    "    H = -Ga+2*Gb-Gc\n",
    "    V = H.T\n",
    "\n",
    "\n",
    "    GGa = imrotate2(Ga, 45, 'bicubic', 'crop')\n",
    "    GGa = GGa/sum(sum(GGa))\n",
    "    GGb = imrotate2(Gb, 45, 'bicubic', 'crop')\n",
    "    GGb = GGb/sum(sum(GGb))\n",
    "    GGc = imrotate2(Gc, 45, 'bicubic', 'crop')\n",
    "    GGc = GGc/sum(sum(GGc))\n",
    "    R = -GGa+2*GGb-GGc\n",
    "    GGa = imrotate2(Ga, -45, 'bicubic', 'crop')\n",
    "    GGa = GGa/sum(sum(GGa))\n",
    "    GGb = imrotate2(Gb, -45, 'bicubic', 'crop')\n",
    "    GGb = GGb/sum(sum(GGb))\n",
    "    GGc = imrotate2(Gc, -45, 'bicubic', 'crop')\n",
    "    GGc = GGc/sum(sum(GGc))\n",
    "    L = -GGa+2*GGb-GGc\n",
    "\n",
    "    hout = filt2(H,pyr)\n",
    "    vout = filt2(V,pyr)\n",
    "    lout = filt2(L,pyr)\n",
    "    rout = filt2(R,pyr)\n",
    "\n",
    "    hvdd = hout, vout, lout, rout\n",
    "\n",
    "    return hvdd\n",
    "\n",
    "\n",
    "def entropy(x, nbins=None):\n",
    "    nsamples = x.shape[0]\n",
    "    \n",
    "    if nbins is None:\n",
    "        nbins = int(np.ceil(np.sqrt(nsamples)))\n",
    "\n",
    "    ref_range = (x.min(), x.max())\n",
    "    ref_hist, _ = np.histogram(x, bins=nbins, range=ref_range)\n",
    "    \n",
    "    ref_hist = ref_hist / float(np.sum(ref_hist))\n",
    "    ref_hist = ref_hist[np.nonzero(ref_hist)]\n",
    "    ref_ent = -np.sum(ref_hist * np.log(ref_hist))\n",
    "\n",
    "    return ref_ent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f082b807",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Clutter():\n",
    "    def __init__(self, inputImage, numlevels=3, contrast_filt_sigma=1, contrast_pool_sigma=None, color_pool_sigma=3):\n",
    "        \n",
    "        self.inputImage = inputImage\n",
    "        self.numlevels = numlevels\n",
    "        self.contrast_filt_sigma = contrast_filt_sigma\n",
    "        self.contrast_pool_sigma = 3 * contrast_filt_sigma if contrast_pool_sigma is None else contrast_pool_sigma\n",
    "        self.color_pool_sigma = color_pool_sigma\n",
    "        self.orient_pool_sigma = 7/2\n",
    "        \n",
    "        if isinstance(inputImage, str): \n",
    "            # Test : passed\n",
    "            self.im = cv2.imread(inputImage)\n",
    "            if self.im is None:\n",
    "                raise ValueError(f'Unable to open {inputImage} image file.')     \n",
    "            self.im = cv2.cvtColor(self.im, cv2.COLOR_BGR2RGB)\n",
    "            \n",
    "        elif isinstance(inputImage,np.ndarray):\n",
    "            self.im = inputImage\n",
    "               \n",
    "\n",
    "        self.m, self.n, self.d = self.im.shape\n",
    "        if self.d == 3:\n",
    "            \n",
    "            self.Lab = RGB2Lab(self.im)\n",
    "            Lab_float = self.Lab.astype(np.float32)\n",
    "\n",
    "            self.L, self.a, self.b = cv2.split(Lab_float)\n",
    "\n",
    "            pyr = pt.pyramids.GaussianPyramid(self.L, height=self.numlevels)\n",
    "            self.L_pyr = pyr.pyr_coeffs\n",
    "\n",
    "            pyr = pt.pyramids.GaussianPyramid(self.a, height=self.numlevels)\n",
    "            self.a_pyr = pyr.pyr_coeffs\n",
    "\n",
    "            pyr = pt.pyramids.GaussianPyramid(self.b, height=self.numlevels)\n",
    "            self.b_pyr = pyr.pyr_coeffs\n",
    "            \n",
    "            self.RRLab = [self.L_pyr, self.a_pyr, self.b_pyr] \n",
    "\n",
    "        else: \n",
    "            self.L = self.im  \n",
    "            pyr = pt.pyramids.GaussianPyramid(L, height=numlevels)\n",
    "            self.L_pyr = pyr.pyr_coeffs\n",
    "            print ('Input image appears to be grayscale, so you can only use contrast clutter method\\n')\n",
    "            \n",
    "    \n",
    "    \n",
    "    def collapse(self, clutter_levels):\n",
    "        \n",
    "        kernel_1d = np.array([[0.05, 0.25, 0.4, 0.25, 0.05]])\n",
    "        kernel_2d = conv2(kernel_1d, kernel_1d.T)\n",
    "\n",
    "        clutter_map = clutter_levels[0]\n",
    "        for scale in range(1,len(clutter_levels)):\n",
    "            clutter_here = clutter_levels[scale]\n",
    "\n",
    "            for kk in range(scale, 0, -1):\n",
    "                clutter_here = pt.upConv(image=clutter_here, filt=kernel_2d, edge_type='reflect1', step=[2,2], start=[0,0])\n",
    "\n",
    "            common_sz = min(clutter_map.shape[0], clutter_here.shape[0]), min(clutter_map.shape[1], clutter_here.shape[1])\n",
    "            for i in range(0, common_sz[0]):\n",
    "                for j in range(0, common_sz[1]):\n",
    "                     clutter_map[i][j] = max(clutter_map[i][j], clutter_here[i][j])\n",
    "\n",
    "    \n",
    "        return clutter_map\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    def display(self, method=''):\n",
    "        \n",
    "        \n",
    "        if method == 'color':\n",
    "            clutter_map = self.color_clutter_map\n",
    "            clutter_levels = self.color_clutter_levels\n",
    "            \n",
    "        elif method == 'contrast':\n",
    "            clutter_map = self.contrast_clutter_map\n",
    "            clutter_levels = self.contrast_clutter_levels\n",
    "\n",
    "        elif method == 'orientation':\n",
    "            clutter_map = self.orientation_clutter_map\n",
    "            clutter_levels = self.orientation_clutter_levels\n",
    "        \n",
    "        elif method == 'combine':\n",
    "            clutter_levels = None\n",
    "            clutter_map = self.clutter_map_fc\n",
    "        \n",
    "        else:\n",
    "            raise ValueError(\"method is not given or incorrect, should be selected from this list: ['color','contrast','orientation', 'combine']\")\n",
    "            \n",
    "        min_min = np.mean(clutter_map)\n",
    "        max_max = np.max(clutter_map)\n",
    "\n",
    "        if clutter_levels is not None:\n",
    "            numlevels = len(clutter_levels)\n",
    "            size = clutter_map.shape[::-1]\n",
    "            if numlevels > 8:\n",
    "                raise ValueError('too many levels!!')\n",
    "\n",
    "\n",
    "            for scale in range(numlevels):\n",
    "                arr = clutter_levels[scale]\n",
    "                new_arr = normlize(arr)\n",
    "                new_PIL = Image.fromarray(new_arr)\n",
    "                new_PIL = new_PIL.resize(size, Image.ANTIALIAS)\n",
    "                new_PIL.save(f'{method} at level {scale}.png')\n",
    "\n",
    "        new_arr = normlize(clutter_map)\n",
    "        new_PIL = Image.fromarray(new_arr)\n",
    "        new_PIL.save(f'collapsed {method} map.png')\n",
    "\n",
    "\n",
    "    def computeColorClutter(self):\n",
    "        \n",
    "        covMx = {}\n",
    "        self.color_clutter_levels = [0] * self.numlevels\n",
    "        DL = [0] * self.numlevels\n",
    "        Da = [0] * self.numlevels\n",
    "        Db = [0] * self.numlevels\n",
    "\n",
    "\n",
    "        deltaL2 = 0.0007 ** 2\n",
    "        deltaa2 = 0.1 ** 2\n",
    "        deltab2 = 0.05 ** 2\n",
    "\n",
    "        bigG = RRgaussfilter1D(round(2*self.color_pool_sigma), self.color_pool_sigma)\n",
    "\n",
    "        for i in range(0, self.numlevels):\n",
    "            DL[i] = RRoverlapconv(bigG, self.L_pyr[(i,0)])\n",
    "            DL[i] = RRoverlapconv(bigG.T, DL[i])   # E(L)\n",
    "            Da[i] = RRoverlapconv(bigG, self.a_pyr[(i,0)])\n",
    "            Da[i] = RRoverlapconv(bigG.T, Da[i])   # E(a)\n",
    "            Db[i] = RRoverlapconv(bigG, self.b_pyr[(i,0)]);\n",
    "            Db[i] = RRoverlapconv(bigG.T, Db[i])    # E(b)\n",
    "\n",
    "\n",
    "            # dict idea\n",
    "            covMx[(i,0,0)] = RRoverlapconv(bigG, self.L_pyr[(i,0)] ** 2)\n",
    "            covMx[(i,0,0)] = RRoverlapconv(bigG.T, covMx[(i,0,0)]) - DL[i] ** 2 + deltaL2  # cov(L,L) + deltaL2\n",
    "            covMx[(i,0,1)] = RRoverlapconv(bigG, self.L_pyr[(i,0)] * self.a_pyr[(i,0)])\n",
    "            covMx[(i,0,1)] = RRoverlapconv(bigG.T, covMx[(i,0,1)]) - DL[i] * Da[i]        # cov(L,a)\n",
    "            covMx[(i,0,2)] = RRoverlapconv(bigG, self.L_pyr[(i,0)] * self.b_pyr[(i,0)])\n",
    "            covMx[(i,0,2)] = RRoverlapconv(bigG.T, covMx[(i,0,2)]) - DL[i] * Db[i]        # cov(L,b)\n",
    "            covMx[(i,1,1)] = RRoverlapconv(bigG, self.a_pyr[(i,0)] ** 2)\n",
    "            covMx[(i,1,1)] = RRoverlapconv(bigG.T, covMx[(i,1,1)]) - Da[i] ** 2 + deltaa2  # cov(a,a) + deltaa2\n",
    "            covMx[(i,1,2)] = RRoverlapconv(bigG, self.a_pyr[(i,0)] * self.b_pyr[(i,0)])\n",
    "            covMx[(i,1,2)] = RRoverlapconv(bigG.T, covMx[(i,1,2)]) - Da[i] * Db[i]        # cov(a,b)\n",
    "            covMx[(i,2,2)] = RRoverlapconv(bigG, self.b_pyr[(i,0)] ** 2)    \n",
    "            covMx[(i,2,2)] = RRoverlapconv(bigG.T, covMx[(i,2,2)]) - Db[i] ** 2 + deltab2;  # cov(b,b) + deltab2\n",
    "\n",
    "\n",
    "            detIm = covMx[(i,0,0)]*(covMx[(i,1,1)]*covMx[(i,2,2)]-covMx[(i,1,2)]*covMx[(i,1,2)])\\\n",
    "            - covMx[(i,0,1)]*(covMx[(i,0,1)]*covMx[(i,2,2)]-covMx[(i,1,2)]*covMx[(i,0,2)])\\\n",
    "            + covMx[(i,0,2)]*(covMx[(i,0,1)]*covMx[(i,1,2)]-covMx[(i,1,1)]*covMx[(i,0,2)])\n",
    "\n",
    "\n",
    "            self.color_clutter_levels[i] = np.sqrt(detIm) ** (1/3)\n",
    "        return self.color_clutter_levels\n",
    "    \n",
    "\n",
    "    def colorClutter(self, color_pix=0):\n",
    "        self.color_pix = color_pix\n",
    "        self.color_clutter_levels = self.computeColorClutter()\n",
    "        self.color_clutter_map = self.collapse(self.color_clutter_levels)\n",
    "        \n",
    "                \n",
    "        if self.color_pix==1:\n",
    "            self.display(method='color')\n",
    "\n",
    "        return self.color_clutter_levels, self.color_clutter_map\n",
    "\n",
    "    \n",
    "    def contrastClutter(self, contrast_pix=0):\n",
    "        self.contrast_pix = contrast_pix\n",
    "        contrast = RRcontrast1channel(self.L_pyr, self.contrast_filt_sigma)\n",
    "\n",
    "        m, n = len(contrast), 1\n",
    "        self.contrast_clutter_levels = [0] * m\n",
    "        bigG = RRgaussfilter1D(round(self.color_pool_sigma*2), self.color_pool_sigma)\n",
    "\n",
    "        for scale in range(0,m):\n",
    "            for channel in range(0,n):\n",
    "        #         var(X) = E(X.^2) - E(X).^2\n",
    "        #         get E(X) by filtering X with a 1-D Gaussian window separably in x and y directions\n",
    "                meanD = RRoverlapconv(bigG, contrast[scale])\n",
    "                meanD = RRoverlapconv(bigG.T, meanD)\n",
    "        #         get E(X.^2) by filtering X.^2 with a 1-D Gaussian window separably in x and y directions\n",
    "                meanD2 = RRoverlapconv(bigG, contrast[scale] ** 2)\n",
    "                meanD2 = RRoverlapconv(bigG.T, meanD2)\n",
    "\n",
    "        #         get variance by var(X) = E(X.^2) - E(X).^2\n",
    "                stddevD = np.sqrt(abs(meanD2 - meanD ** 2))\n",
    "                self.contrast_clutter_levels[scale] = stddevD\n",
    "\n",
    "        self.contrast_clutter_map = self.collapse(self.contrast_clutter_levels)\n",
    "        \n",
    "        \n",
    "        if self.contrast_pix==1:\n",
    "            self.display(method='contrast')\n",
    "\n",
    "        return self.contrast_clutter_levels, self.contrast_clutter_map\n",
    "    \n",
    "\n",
    "    def RROrientationOppEnergy(self):\n",
    "        \"\"\"\n",
    "        OPP_ENERGY    This runs the oriented opponent energy calculation that\n",
    "        serves as the first stages in Bergen & Landy's (1990)\n",
    "        texture segmentor, except it uses DOOG filters (which actually\n",
    "        don't work as well, but at least we can more easily control the\n",
    "        scale).\n",
    "        \"\"\"\n",
    "\n",
    "        hvdd = [0] * self.numlevels\n",
    "        hv = [0] * self.numlevels\n",
    "        dd = [0] * self.numlevels\n",
    "        out = [0] * self.numlevels\n",
    "        total = [0] * self.numlevels\n",
    "\n",
    "        noise = 1.0    # Was 1.5\n",
    "        filterScale = 16/14*1.75\n",
    "        poolScale = 1.75\n",
    "    #     These probably seem like arbitrary numbers, but it's just trying to get\n",
    "    #     three very different feature extraction methods to operate at basically\n",
    "    #     the same scales.\n",
    "\n",
    "\n",
    "        for scale in range(0, self.numlevels):\n",
    "    #         Check this is the right order for Landy/Bergen. RRR\n",
    "            hvdd[scale] = orient_filtnew(self.L_pyr[(scale,0)],filterScale) \n",
    "    #         filt with 4 oriented filters 0, 45, 90, 135.  Was sigma = 16/14, orient_filtnew,\n",
    "    #         then 16/14*1.75 to match contrast and other scales.\n",
    "    #         Eventually make this sigma a variable that's passed to this routine.\n",
    "    #         hvdd[scale] is the 4 output images concatenated together, \n",
    "    #         in the order horizontal, vertical, up-left, and down-right.\n",
    "\n",
    "            hvdd[scale] = [x ** 2 for x in hvdd[scale]]    #local energy\n",
    "            hvdd[scale] = poolnew(hvdd[scale], poolScale) #Pools with a gaussian filter.  Was effectively sigma=1, then 1.75 to match 1.75 above.\n",
    "    #         RRR Should look at these results and see if this is the right amount of\n",
    "    #         pooling for the new filters.  It was right for the Landy-Bergen\n",
    "    #         filters.\n",
    "            hv[scale] = HV(hvdd[scale]) # get the difference image between horizontal and vertical: H-V (0-90)\n",
    "            dd[scale] = DD(hvdd[scale]) # get the difference image between right and left: R-L (45-135)\n",
    "    #         Normalize by the total response at this scale, assuming the total\n",
    "    #         response is high enough.  If it's too low, we'll never see this\n",
    "    #         orientation.  I'm not sure what to do here -- set it to zeros and\n",
    "    #         it's like that's the orientation.  Maybe output the total response\n",
    "    #         and decide what to do later.  RRR\n",
    "            total[scale] = sumorients(hvdd[scale]) + noise # add noise based upon sumorients at visibility threshold\n",
    "            hv[scale] = hv[scale]/total[scale] # normalize the hv and dd image\n",
    "            dd[scale] = dd[scale]/total[scale]\n",
    "            out[scale] = hv[scale], dd[scale] # out is the 2 output images concatenated together, in the order of hv, dd\n",
    "\n",
    "        return out\n",
    "\n",
    "\n",
    "    def computeOrientationClutter(self):\n",
    "        \"\"\"\n",
    "        computes the orientation clutter maps. Returns:\n",
    "        clutter_levels, a cell structure, containing the orientation clutter at a \n",
    "        number of scales specified by numlevels;  -- cell(numlevels,1) --, the n'th \n",
    "        level of which can be accessed using clutter_levels{n}{1}\n",
    "\n",
    "        input:\n",
    "            L_pyr\n",
    "            the Gaussian pyramid of L (from CIELab color space)\n",
    "            the Gaussian pyramid is computed by alternately blurring and subsampling the L channels\n",
    "\n",
    "        Orientation clutter is computed as the \"volume\" of an orientation distribution\n",
    "        ellipsoid, which is the determinant of covariance matrix. Treats cos(2 theta)\n",
    "        and sin(2 theta) (computed from OrientedOppEnergy) as a two-vector, and gets\n",
    "        The covariance of this two-vector.  The covariance \n",
    "        matrix can be computed efficiently through linear filtering. More \n",
    "        specifically, cov(X,Y) = E(XY)-E(X)E(Y), where E (expectation value) \n",
    "        can be approximated by filtering with a Gaussian window. \n",
    "        poolScale is set to 7/2.\n",
    "\n",
    "        Reference (though there is no orientation clutter in this reference):\n",
    "        Ruth Rosenholtz, Yuanzhen Li, Jonathan Mansfield, and Zhenlan Jin. \n",
    "        Feature Congestion: A Measure of Display Clutter. CHI '05: Proc. of the SIGCHI conference \n",
    "        on Human factors in computing systems. May 2005. 761-770.  \n",
    "\n",
    "        Based upon RRcomputeOrientationSaliency\n",
    "        Ruth Rosenholtz, May 2006\n",
    "\n",
    "        This currently seems far too dependent on luminance contrast.  Check into\n",
    "        why this is so -- I thought we were normalizing by local contrast.\n",
    "\n",
    "        \"\"\"\n",
    "\n",
    "        noise = 0.001  # Was eps, but that gave too much orientation noise in the saliency maps.  Then changed to 0.000001\n",
    "        poolScale = 7/2\n",
    "\n",
    "        numlevels = len(self.L_pyr);\n",
    "        Dc = [0] * numlevels  # mean \"cos 2 theta\" at distractor scale\n",
    "        Ds = [0] * numlevels  # mean \"sin 2 theta\" at distractor scale\n",
    "\n",
    "    #     Get approximations to cos(2theta) and sin(2theta) from oriented opponent\n",
    "    #     energy, at each of the numlevels of the pyramid\n",
    "        angles = self.RROrientationOppEnergy()\n",
    "\n",
    "    #     Compute the two-vector [meancos, meansin] at each scale, as well as the\n",
    "    #     things we need to compute the mean and covariance of this two-vector at\n",
    "    #     the larger, distractor scale.\n",
    "\n",
    "        bigG = RRgaussfilter1D(round(8*poolScale), 4*poolScale)\n",
    "        maxbigG = max(bigG) ** 2\n",
    "\n",
    "\n",
    "        covMx = {}\n",
    "        self.orientation_clutter_levels = [0] * numlevels\n",
    "\n",
    "        for i in range(0,numlevels):\n",
    "            cmx = angles[i][0]\n",
    "            smx = angles[i][1]\n",
    "\n",
    "    #         Pool to get means at distractor scale. In pooling, don't pool over the target\n",
    "    #         region (implement this by pooling with a big Gaussian, then\n",
    "    #         subtracting the pooling over the target region computed above.  Note,\n",
    "    #         however, that we first need to scale the target region pooling so\n",
    "    #         that its peak is the same height as this much broader Gaussian used\n",
    "    #         to pool over the distractor region.\n",
    "\n",
    "            Dc[i] = RRoverlapconv(bigG, cmx)\n",
    "            Dc[i] = RRoverlapconv(bigG.T, Dc[i])\n",
    "            Ds[i] = RRoverlapconv(bigG, smx)\n",
    "            Ds[i] = RRoverlapconv(bigG.T, Ds[i])\n",
    "\n",
    "    #         Covariance matrix elements.  Compare with computations in\n",
    "    #         RRStatisticalSaliency.  I tried to match computeColorClutter, but I\n",
    "    #         don't remember the meaning of some of the terms I removed.  XXX\n",
    "            covMx[(i,0,0)] = RRoverlapconv(bigG, cmx ** 2)\n",
    "            covMx[(i,0,0)] = RRoverlapconv(bigG.T, covMx[(i,0,0)]) - Dc[i] ** 2 + noise\n",
    "            covMx[(i,0,1)] = RRoverlapconv(bigG, cmx * smx)\n",
    "            covMx[(i,0,1)] = RRoverlapconv(bigG.T, covMx[(i,0,1)]) - Dc[i] * Ds[i]\n",
    "            covMx[(i,1,1)] = RRoverlapconv(bigG, smx ** 2)\n",
    "            covMx[(i,1,1)] = RRoverlapconv(bigG.T, covMx[(i,1,1)]) - Ds[i] ** 2 + noise\n",
    "\n",
    "    #         Get determinant of covariance matrix, which is the volume of the\n",
    "    #         covariance ellipse\n",
    "            detIm = covMx[(i,0,0)] * covMx[(i,1,1)] - covMx[(i,0,1)] ** 2\n",
    "    #         Take the square root considering variance is squared, and the square\n",
    "    #         root again, since this is the area and the contrast measure is a \"length\"\n",
    "            self.orientation_clutter_levels[i] = detIm ** (1/4)\n",
    "\n",
    "\n",
    "        return self.orientation_clutter_levels\n",
    "    \n",
    "\n",
    "    def orientationClutter(self, orient_pix=0):\n",
    "        self.orient_pix = orient_pix\n",
    "        pool_sigma = 7/2\n",
    "        \n",
    "        self.orientation_clutter_levels = self.computeOrientationClutter()\n",
    "        self.orientation_clutter_map = self.collapse(self.orientation_clutter_levels)\n",
    "        \n",
    "        if self.orient_pix==1:\n",
    "            self.display(method='orientation')\n",
    "\n",
    "        return self.orientation_clutter_levels, self.orientation_clutter_map\n",
    "    \n",
    "    def computeClutter(self, color_pix=0, contrast_pix=0, orient_pix=0):\n",
    "        # compute the color clutter\n",
    "        color_clutter_levels, color_clutter_map = self.colorClutter(color_pix = color_pix)\n",
    "        # compute the contrast clutter\n",
    "        contrast_clutter_levels, contrast_clutter_map = self.contrastClutter(contrast_pix = contrast_pix)\n",
    "        #compute the orientation clutter\n",
    "        orient_clutter_levels, orientation_clutter_map = self.orientationClutter(orient_pix = orient_pix)\n",
    "\n",
    "        # output them in cell structures\n",
    "        color_clutter = [color_clutter_levels, color_clutter_map]\n",
    "        contrast_clutter = [contrast_clutter_levels, contrast_clutter_map]\n",
    "        orientation_clutter = [orient_clutter_levels, orientation_clutter_map]\n",
    "\n",
    "        return color_clutter, contrast_clutter, orientation_clutter\n",
    "    \n",
    "    \n",
    "    def getClutter_FC(self, p=1, pix=0):\n",
    "        color_clutter, contrast_clutter, orient_clutter = self.computeClutter()\n",
    "        self.clutter_map_fc = color_clutter[1] / 0.2088 + contrast_clutter[1] / 0.0660 + orient_clutter[1] / 0.0269\n",
    "        self.clutter_scalar_fc = np.mean(self.clutter_map_fc ** p) ** (1 / p) #element wise\n",
    "        \n",
    "        if pix==1:\n",
    "            self.display(method='combine')\n",
    "        return self.clutter_scalar_fc, self.clutter_map_fc\n",
    "\n",
    "\n",
    "    def band_entropy(self, map_, wlevels, wor):\n",
    "        \"\"\"\n",
    "        en_band = band_entropy(map_, wlevels, wor)\n",
    "        Inputs: \n",
    "            \"map_\": a monochromatic image\n",
    "            \"wlevels\": the number of spatial scales for the subband decomposition\n",
    "            \"wor\": the number of orientations for the subband decomposition\n",
    "        Outputs:\n",
    "            \"en_band\": a vector containing Shannon entropies of all the subbands\n",
    "\n",
    "        Reference: Ruth Rosenholtz, Yuanzhen Li, and Lisa Nakano. \"Measuring\n",
    "        Visual Clutter\". To appear in Journal of Vision, 7(2).\n",
    "\n",
    "        Ruth Rosenholtz, Yuanzhen Li, and Lisa Nakano, March 2007.\n",
    "        \"\"\"\n",
    "        \n",
    "        # decompose the image into subbands:\n",
    "        self.SFpyr = pt.pyramids.SteerablePyramidFreq(map_, height=wlevels, order=wor-1)\n",
    "        S = self.SFpyr.pyr_coeffs\n",
    "        \n",
    "        en_band = []\n",
    "        for ind in S.keys():\n",
    "            en_band.append(entropy(S[ind].ravel()))\n",
    "            \n",
    "\n",
    "        return en_band\n",
    "    \n",
    "    \n",
    "    def getClutter_SE(self, wlevels=3, wght_chrom=0.0625):\n",
    "        \"\"\"\n",
    "        [clutter_se] = getClutter_SE(map_name, [wlevels], [wght_chrom])\n",
    "        Subband Entropy measure of visual clutter.\n",
    "        Outputs:\n",
    "            \"clutter_se\": the subband entropy clutter of the image.\n",
    "        Inputs: \n",
    "            \"map_name\": input image. It can be a string (file name of the image),\n",
    "            or an array (the image itself).\n",
    "            \"wlevels\":  the number of scales (optional, default 3)\n",
    "            \"wght_chrom\": the weight on chrominance (optional, default 0.0625)\n",
    "\n",
    "        This measure (Subband Entropy) of visual clutter is based on the notion\n",
    "        that clutter is related to the number of bits required for subband\n",
    "        (wavelet) image coding.\n",
    "\n",
    "        Reference: \n",
    "        Ruth Rosenholtz, Yuanzhen Li, and Lisa Nakano. \"Measuring Visual Clutter\". \n",
    "        Journal of Vision, 7(2), 2007. http://www.journalofvision.com/7/2/\n",
    "        \n",
    "        Ruth Rosenholtz, Yuanzhen Li, and Lisa Nakano, March 2007.\n",
    "        \"\"\"\n",
    "\n",
    "        wor = 4;\n",
    "    #      luminance channel\n",
    "        en_band = self.band_entropy(self.L, wlevels, wor)\n",
    "        clutter_se = np.mean(en_band)\n",
    "\n",
    "        if self.d == 1:\n",
    "            return clutter_se\n",
    "\n",
    "    #     chrominance channels:\n",
    "        for jj in [self.a, self.b]:\n",
    "            if np.max(jj)-np.min(jj) < 0.008:\n",
    "                jj = np.zeros_like(jj)\n",
    "\n",
    "            en_band = self.band_entropy(jj, wlevels, wor)\n",
    "            clutter_se = clutter_se + wght_chrom * np.mean(en_band)\n",
    "\n",
    "            clutter_se = clutter_se/(1+2*wght_chrom)\n",
    "        return clutter_se"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "99eed8e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "clt = Clutter('test2.png', numlevels=3, contrast_filt_sigma=1, contrast_pool_sigma=3, color_pool_sigma=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bd8ed487",
   "metadata": {},
   "outputs": [],
   "source": [
    "color_clutter = clt.colorClutter(color_pix=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "03fd030b",
   "metadata": {},
   "outputs": [],
   "source": [
    "contrast_clutter = clt.contrastClutter(contrast_pix=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cbc04b4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "orientation_clutter = clt.orientationClutter(orient_pix=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "87cdb453",
   "metadata": {},
   "outputs": [],
   "source": [
    "color_clutter, contrast_clutter, orientation_clutter = clt.computeClutter(color_pix=1, contrast_pix=1, orient_pix=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7883965e",
   "metadata": {},
   "outputs": [],
   "source": [
    "clutter_scalar_fc, clutter_map_fc = clt.getClutter_FC(p=1, pix=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0e47c940",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.104007577930963"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clutter_scalar_fc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "980c17a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.9743949219075123"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clt.getClutter_SE(wlevels=3, wght_chrom=0.0625)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d7ab7c8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
