{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "07e40646",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! pip install pyrtools\n",
    "# ! pip install opencv-python\n",
    "# pip install Pillow\n",
    "# ! pip install scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c9b98c97",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import pyrtools as pt\n",
    "from PIL import Image\n",
    "from scipy import signal"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d55a3aaf",
   "metadata": {},
   "source": [
    "## COLOR CLUTTER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "09b14dc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv2(x, y, mode=None):\n",
    "    \n",
    "    if mode == 'same':\n",
    "        return np.rot90(signal.convolve2d(np.rot90(x, 2), np.rot90(y, 2), mode=mode), 2)\n",
    "    else:\n",
    "        return signal.convolve2d(x, y)\n",
    "        \n",
    "\n",
    "def RRoverlapconv(kernel, in_):\n",
    "    out = conv2(in_, kernel, mode='same')\n",
    "    rect = np.ones_like(in_)\n",
    "\n",
    "    overlapsum = conv2(rect, kernel, 'same')\n",
    "    out = np.sum(kernel) * out / overlapsum\n",
    "    return out\n",
    "\n",
    "\n",
    "\n",
    "def RRgaussfilter1D(halfsupport, sigma, center=0):\n",
    "    t = list(range(-halfsupport, halfsupport+1))\n",
    "    kernel = [np.exp(-(x-center) **2 /(2* sigma ** 2)) for x in t]\n",
    "    kernel = kernel/sum(kernel)\n",
    "    \n",
    "    return kernel[:,None]\n",
    "    \n",
    "\n",
    "def computeColorClutter(L_pyr, a_pyr, b_pyr, sigD):\n",
    "    \n",
    "    numlevels = len(L_pyr);\n",
    "\n",
    "    \n",
    "    if len(a_pyr)!=numlevels or len(b_pyr)!=numlevels:\n",
    "        print('L, a, and b channels must have the same number of levels in the Gaussian pyramid\\n')\n",
    "\n",
    "    covMx = {}\n",
    "    clutter_levels = [0] * numlevels\n",
    "    DL = [0] * numlevels\n",
    "    Da = [0] * numlevels\n",
    "    Db = [0] * numlevels\n",
    "    \n",
    "    \n",
    "    deltaL2 = 0.0007 ** 2\n",
    "    deltaa2 = 0.1 ** 2\n",
    "    deltab2 = 0.05 ** 2\n",
    "    \n",
    "    bigG = RRgaussfilter1D(round(2*sigD), sigD)\n",
    "    \n",
    "    for i in range(0, numlevels):\n",
    "        DL[i] = RRoverlapconv(bigG, L_pyr[(i,0)])\n",
    "        DL[i] = RRoverlapconv(bigG.T, DL[i])   # E(L)\n",
    "        Da[i] = RRoverlapconv(bigG, a_pyr[(i,0)])\n",
    "        Da[i] = RRoverlapconv(bigG.T, Da[i])   # E(a)\n",
    "        Db[i] = RRoverlapconv(bigG, b_pyr[(i,0)]);\n",
    "        Db[i] = RRoverlapconv(bigG.T, Db[i])    # E(b)\n",
    "\n",
    "    \n",
    "        # dict idea\n",
    "        covMx[(i,0,0)] = RRoverlapconv(bigG, L_pyr[(i,0)] ** 2)\n",
    "        covMx[(i,0,0)] = RRoverlapconv(bigG.T, covMx[(i,0,0)]) - DL[i] ** 2 + deltaL2  # cov(L,L) + deltaL2\n",
    "        covMx[(i,0,1)] = RRoverlapconv(bigG, L_pyr[(i,0)] * a_pyr[(i,0)])\n",
    "        covMx[(i,0,1)] = RRoverlapconv(bigG.T, covMx[(i,0,1)]) - DL[i] * Da[i]        # cov(L,a)\n",
    "        covMx[(i,0,2)] = RRoverlapconv(bigG, L_pyr[(i,0)] * b_pyr[(i,0)])\n",
    "        covMx[(i,0,2)] = RRoverlapconv(bigG.T, covMx[(i,0,2)]) - DL[i] * Db[i]        # cov(L,b)\n",
    "        covMx[(i,1,1)] = RRoverlapconv(bigG, a_pyr[(i,0)] ** 2)\n",
    "        covMx[(i,1,1)] = RRoverlapconv(bigG.T, covMx[(i,1,1)]) - Da[i] ** 2 + deltaa2  # cov(a,a) + deltaa2\n",
    "        covMx[(i,1,2)] = RRoverlapconv(bigG, a_pyr[(i,0)] * b_pyr[(i,0)])\n",
    "        covMx[(i,1,2)] = RRoverlapconv(bigG.T, covMx[(i,1,2)]) - Da[i] * Db[i]        # cov(a,b)\n",
    "        covMx[(i,2,2)] = RRoverlapconv(bigG, b_pyr[(i,0)] ** 2)    \n",
    "        covMx[(i,2,2)] = RRoverlapconv(bigG.T, covMx[(i,2,2)]) - Db[i] ** 2 + deltab2;  # cov(b,b) + deltab2\n",
    "\n",
    "    \n",
    "\n",
    "        \n",
    "        detIm = covMx[(i,0,0)]*(covMx[(i,1,1)]*covMx[(i,2,2)]-covMx[(i,1,2)]*covMx[(i,1,2)])\\\n",
    "        - covMx[(i,0,1)]*(covMx[(i,0,1)]*covMx[(i,2,2)]-covMx[(i,1,2)]*covMx[(i,0,2)])\\\n",
    "        + covMx[(i,0,2)]*(covMx[(i,0,1)]*covMx[(i,1,2)]-covMx[(i,1,1)]*covMx[(i,0,2)])\n",
    "\n",
    "        \n",
    "        clutter_levels[i] = np.sqrt(detIm) ** (1/3)\n",
    "    return clutter_levels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6e382052",
   "metadata": {},
   "outputs": [],
   "source": [
    "def colorClutter(inputImage, numlevels, pool_sigma=3, pix=1):\n",
    "    \n",
    "    if isinstance(inputImage, list):\n",
    "        L_pyr = inputImage[0]\n",
    "        a_pyr = inputImage[1]\n",
    "        b_pyr = inputImage[2]\n",
    "        \n",
    "    else:\n",
    "        pass #TODO\n",
    "        return 0\n",
    "    \n",
    "    clutter_levels = computeColorClutter(L_pyr, a_pyr, b_pyr, pool_sigma);\n",
    "    \n",
    "    kernel_1d = np.array([[0.05, 0.25, 0.4, 0.25, 0.05]])\n",
    "    kernel_2d = conv2(kernel_1d, kernel_1d.T)\n",
    "    \n",
    "    clutter_map = clutter_levels[0]\n",
    "    for scale in range(1,numlevels):\n",
    "        clutter_here = clutter_levels[scale]\n",
    "        \n",
    "        for kk in range(scale, 0, -1):\n",
    "            # TODO\n",
    "#             start= np.array([[0,0]])\n",
    "#             step = np.array([[2,2]])\n",
    "#             stop = step * (np.floor( (start - np.ones_like(start))/step) + len(clutter_here))\n",
    "            clutter_here = pt.upConv(image=clutter_here, filt=kernel_2d, edge_type='reflect1', step=[2,2], start=[0,0])\n",
    "    \n",
    "        common_sz = min(clutter_map.shape[0], clutter_here.shape[0]), min(clutter_map.shape[1], clutter_here.shape[1])\n",
    "        for i in range(0, common_sz[0]):\n",
    "            for j in range(0, common_sz[1]):\n",
    "                 clutter_map[i][j] = max(clutter_map[i][j], clutter_here[i][j])\n",
    "\n",
    "    \n",
    "    return clutter_levels, clutter_map"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c6dbecb",
   "metadata": {},
   "source": [
    "## CONTRAST CLUTTER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "073b004d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test is passed: Diffrent test cases manually checked by MATLAB\n",
    "def DoG1filter(a,sigma):\n",
    "    \n",
    "    sigi = 0.71 * sigma\n",
    "    sigo = 1.14 * sigma\n",
    "    \n",
    "    t = range(-a, a+1)\n",
    "    \n",
    "    gi = [np.exp(-x ** 2 /(2 * sigi ** 2)) for x in t]\n",
    "    gi = gi/sum(gi)\n",
    "    go = [np.exp(- x ** 2/(2 * sigo ** 2)) for x in t]\n",
    "    go = go/sum(go)\n",
    "    return gi,go"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "148f1e92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test is passed: Diffrent test cases manually checked by MATLAB\n",
    "def addborder(im,xbdr,ybdr,arg):\n",
    "    \"\"\"\n",
    "    imnew = addborder(im,xborder,yborder,arg)  Make image w/added border.\n",
    "    imnew = addborder(im,5,5,128)  Add 5 wide border of val 128.\n",
    "    imnew = addborder (im,5,5,'even')  Even reflection.\n",
    "    imnew = addborder (im,5,5,'odd')  Odd reflection.\n",
    "    imnew = addborder (im,5,5,'wrap')  Wraparound.\n",
    "    \"\"\"\n",
    "    ysize, xsize = im.shape\n",
    "    \n",
    "    \n",
    "#     check thickness\n",
    "    if (xbdr > xsize-1) or (ybdr > ysize-1):\n",
    "        raise ValueError('borders must be thinner than image')\n",
    "    \n",
    "#     if arg is a number, fill border with its value.\n",
    "    if isinstance(arg, (int, float)):\n",
    "        imbig = cv2.copyMakeBorder(im, ybdr,ybdr,xbdr,xbdr, cv2.BORDER_CONSTANT, value=arg)\n",
    "    \n",
    "#     Even reflections\n",
    "    elif arg == 'even':\n",
    "        imbig = cv2.copyMakeBorder(im, ybdr,ybdr,xbdr,xbdr, cv2.BORDER_REFLECT)\n",
    "        \n",
    "#     Odd reflections\n",
    "    elif arg == 'odd':\n",
    "        imbig = cv2.copyMakeBorder(im, ybdr,ybdr,xbdr,xbdr, cv2.BORDER_REFLECT_101)\n",
    "        \n",
    "#    Wraparound\n",
    "    elif arg == 'wrap':\n",
    "        imbig = cv2.copyMakeBorder(im, ybdr,ybdr,xbdr,xbdr, cv2.BORDER_WRAP)\n",
    "    else:\n",
    "        raise ValueError('unknown border style')\n",
    "    return imbig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "65b841e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filt2(kernel, im1, reflect_style='odd'):\n",
    "    \"\"\"\n",
    "    im2 = filt2(kernel,im1,reflect_style)\n",
    "    Improved version of filter2 in MATLAB, which includes reflection.\n",
    "    Default style is 'odd'. Also can be 'even', or 'wrap'.\n",
    "    im2 = filt2(kern,image)  apply kernel with odd reflection (default).\n",
    "    im2 = filt2(kern,image,'even')  Use even reflection.\n",
    "    im2 = filt2(kern,image,128)  Fill with 128's.\n",
    "\n",
    "    Ruth Rosenholtz\n",
    "    \"\"\"\n",
    "    \n",
    "    ky,kx = kernel.shape\n",
    "    iy,ix = im1.shape\n",
    "\n",
    "    # TODO: index should be checked, maybe it needs to be changed 1 pixel (getting back -1)\n",
    "    imbig = addborder(im1, kx, ky, reflect_style)\n",
    "    imbig = conv2(imbig, kernel, 'same')\n",
    "    im2 = imbig[ky:ky+iy, kx:kx+ix]\n",
    "\n",
    "\n",
    "    return im2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e4fd69f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def RRcontrast1channel(pyr, DoG_sigma=2):\n",
    "    \n",
    "    levels = len(pyr)\n",
    "    contrast = [0] * levels\n",
    "    \n",
    "    innerG1, outerG1 = DoG1filter(round(DoG_sigma*3), DoG_sigma)\n",
    "\n",
    "    innerG1 = innerG1[:,None]\n",
    "    outerG1 = outerG1[:,None]\n",
    "\n",
    "    for i in range(0,levels):\n",
    "        inner = filt2(innerG1, pyr[(i,0)])\n",
    "        inner = filt2(innerG1.T, inner)\n",
    "        outer = filt2(outerG1, pyr[(i,0)])\n",
    "        outer = filt2(outerG1.T, outer)\n",
    "        tmp = inner - outer\n",
    "        contrast[i] = abs(tmp)\n",
    " \n",
    "    return contrast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "907a1ed4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def contrastClutter(inputImage, numlevels, filt_sigma, pool_sigma=None, pix=1):\n",
    "    \n",
    "    if pool_sigma is None:\n",
    "        pool_sigma = 3 * filt_sigma\n",
    "\n",
    "    if isinstance(inputImage, list):\n",
    "        L_pyr = inputImage[0]\n",
    "        \n",
    "    else:\n",
    "        if isinstance(inputImage, str):\n",
    "            im = cv2.imread(inputImage)\n",
    "            if im is None:\n",
    "                print('Unable to open %s image file.') #TODO: add logger\n",
    "                return 0\n",
    "\n",
    "        elif isinstance(inputImage,np.ndarray):\n",
    "            im = inputImage\n",
    "             \n",
    "        m, n, d = im.shape\n",
    "        if d == 3:\n",
    "            Lab = cv2.cvtColor(im, cv2.COLOR_RGB2LAB)\n",
    "            L = Lab[:,:,0]\n",
    "        else: \n",
    "            # TODO: should be test\n",
    "            L = im\n",
    "\n",
    "  \n",
    "        pyr = pt.pyramids.GaussianPyramid(L, height=numlevels)\n",
    "        L_pyr = pyr.pyr_coeffs\n",
    "        \n",
    "        # TODO\n",
    "    contrast = RRcontrast1channel(L_pyr, filt_sigma)\n",
    "    \n",
    "    m, n = len(contrast), 1\n",
    "    clutter_levels = [0] * m\n",
    "    bigG = RRgaussfilter1D(round(pool_sigma*2), pool_sigma)\n",
    "    \n",
    "    \n",
    "    \n",
    "    for scale in range(0,m):\n",
    "        for channel in range(0,n):\n",
    "    #         var(X) = E(X.^2) - E(X).^2\n",
    "    #         get E(X) by filtering X with a 1-D Gaussian window separably in x and y directions\n",
    "            meanD = RRoverlapconv(bigG, contrast[scale])\n",
    "            meanD = RRoverlapconv(bigG.T, meanD)\n",
    "    #         get E(X.^2) by filtering X.^2 with a 1-D Gaussian window separably in x and y directions\n",
    "            meanD2 = RRoverlapconv(bigG, contrast[scale] ** 2)\n",
    "            meanD2 = RRoverlapconv(bigG.T, meanD2)\n",
    "\n",
    "    #         get variance by var(X) = E(X.^2) - E(X).^2\n",
    "            stddevD = np.sqrt(abs(meanD2 - meanD ** 2))\n",
    "            clutter_levels[scale] = stddevD\n",
    "\n",
    "            \n",
    "            \n",
    "        \n",
    "    kernel_1d = np.array([[0.05, 0.25, 0.4, 0.25, 0.05]])\n",
    "    kernel_2d = conv2(kernel_1d, kernel_1d.T)\n",
    "    \n",
    "    clutter_map = clutter_levels[0]\n",
    "    for scale in range(1,m):\n",
    "        clutter_here = clutter_levels[scale]\n",
    "        \n",
    "        for kk in range(scale, 0, -1):\n",
    "            # TODO\n",
    "#             start= np.array([[0,0]])\n",
    "#             step = np.array([[2,2]])\n",
    "#             stop = step * (np.floor( (start - np.ones_like(start))/step) + len(clutter_here))\n",
    "            clutter_here = pt.upConv(image=clutter_here, filt=kernel_2d, edge_type='reflect1', step=[2,2], start=[0,0])\n",
    "    \n",
    "        common_sz = min(clutter_map.shape[0], clutter_here.shape[0]), min(clutter_map.shape[1], clutter_here.shape[1])\n",
    "        for i in range(0, common_sz[0]):\n",
    "            for j in range(0, common_sz[1]):\n",
    "                 clutter_map[i][j] = max(clutter_map[i][j], clutter_here[i][j])\n",
    "\n",
    "    return clutter_levels, clutter_map"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f15aae5",
   "metadata": {},
   "source": [
    "## ORIENTATION CLUTTER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "4b54c94d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reduce(image0, kernel=None):\n",
    "    \"\"\"\n",
    "    Reduce: for building Gaussian or Laplacian pyramids. 1-D separable kernels.\n",
    "\n",
    "    imnew = reduce(im0) Reduce w/default kernel: [.05 .25 .4 .25 .05]\n",
    "    imnew = reduce(im0, kern) Reduce with kern; sums to unity.\n",
    "\n",
    "    Ruth Rosenholtz \n",
    "    \"\"\"\n",
    "\n",
    "    \n",
    "    if kernel is None:\n",
    "    #     Default kernel \n",
    "        kernel = [0.05, 0.25, 0.4, 0.25, 0.05]\n",
    "\n",
    "\n",
    "    ysize, xsize = image0.shape\n",
    "\n",
    "    image0 = filt2(kernel,image0) # Filter horizontally. \n",
    "#     filt2 is filter2 with reflection.\n",
    "    image1 = image0[:,range(0,xsize,2)]\n",
    "\n",
    "    image1 = filt2(kernel.T,image1) # Filter vertically.\n",
    "    image2 = image1[range(0,ysize,2),:]\n",
    "\n",
    "    return image2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "2ab68ec8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def RRoverlapconvexpand(in_, kernel=None):\n",
    "    \"\"\"\n",
    "    out = RRoverlapconvexpand(in_)  return an image expanded to double size,\n",
    "    out = RRoverlapconvexpand(in, kernel); specify 1-D kernel with unity sum.\n",
    "    \"\"\"\n",
    "    \n",
    "    if kernel is None:\n",
    "    #     Default kernel \n",
    "        kernel = [0.05, 0.25, 0.4, 0.25, 0.05]\n",
    "\n",
    "    ysize, xsize = in_.shape\n",
    "    kernel = kernel * 2 # kernel sum=2 to account for padding.\n",
    "\n",
    "    tmp = np.zeros([ysize,2*xsize]) # First double the width\n",
    "    k = list(range(0, xsize))\n",
    "    k_2 = [x*2 for x in k]\n",
    "    tmp[:,k_2] = in_[:,k]\n",
    "    tmp = RRoverlapconv(kernel,tmp) # ..and filter horizontally. \n",
    "\n",
    "    out = np.zeros([2*ysize,2*xsize]) # Next double the height\n",
    "    k = list(range(0, ysize))\n",
    "    k_2 = [x*2 for x in k]\n",
    "    out[k_2,:] = tmp[k,:]\n",
    "    out = RRoverlapconv(kernel.T,out) # ..and filter vertically.\n",
    "\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "3e433df4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def HV(in_):\n",
    "    out = in_[0] - in_[1]\n",
    "    return out\n",
    "\n",
    "\n",
    "def DD(in_):\n",
    "    out = in_[3] - in_[2]\n",
    "    return out\n",
    "\n",
    "\n",
    "def sumorients(in_):\n",
    "    out =  in_[0] + in_[1] + in_[2] + in_[3]\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "fab7a330",
   "metadata": {},
   "outputs": [],
   "source": [
    "def poolnew(in_, sigma=None):\n",
    "    \"\"\"\n",
    "    Pools with a gaussian.  Note assumes that input image is actually\n",
    "    4 equal-size images, side by side.\n",
    "\n",
    "    Usage: out = poolnew(input_image, sigma)\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    in1 = in_[0] #H -> first quarter\n",
    "    in2 = in_[1] #V -> second quarter\n",
    "    in3 = in_[2] #L -> third quarter\n",
    "    in4 = in_[3] #R -> last quarter\n",
    "\n",
    "    \n",
    "    if sigma is None:\n",
    "        out1 = reduce(RRoverlapconvexpand(in1))\n",
    "        out2 = reduce(RRoverlapconvexpand(in2))\n",
    "        out3 = reduce(RRoverlapconvexpand(in3))\n",
    "        out4 = reduce(RRoverlapconvexpand(in4))\n",
    "    else:\n",
    "        kernel = RRgaussfilter1D(round(2*sigma), sigma);\n",
    "        out1 = reduce(RRoverlapconvexpand(in1, kernel), kernel);\n",
    "        out2 = reduce(RRoverlapconvexpand(in2, kernel), kernel);\n",
    "        out3 = reduce(RRoverlapconvexpand(in3, kernel), kernel);\n",
    "        out4 = reduce(RRoverlapconvexpand(in4, kernel), kernel);    \n",
    "\n",
    "    out = out1, out2, out3, out4\n",
    "\n",
    "    return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "54f06300",
   "metadata": {},
   "outputs": [],
   "source": [
    "def imrotate(im, angle, method, bbox):\n",
    "    func_method = {'nearest':0,'bilinear':2,'bicubic':3,'cubic':3}\n",
    "    func_bbox = {'loose':True,'crop':False}\n",
    "    PIL_im = Image.fromarray(im)\n",
    "    \n",
    "    im_rot = PIL_im.rotate(angle, expand = func_bbox[bbox], resample = func_method[method])\n",
    "    return np.array(im_rot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "4a6c71b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def orient_filtnew(pyr, sigma=16/14):\n",
    "    \"\"\"\n",
    "    ORIENT_FILTNEW Filters \"pyr\" (in principle, one level of the\n",
    "        Gaussian pyramid generated by gausspyr) with 2nd\n",
    "        derivative filters in 4 directions\n",
    "\n",
    "    Usage: [hvdd] = orient_filt(pyr)\n",
    "        Where hvdd is the 4 output images concatenated \n",
    "        together, in the order horizontal, vertical, up-left,\n",
    "        and down-right.\n",
    "    \"\"\"\n",
    "    \n",
    "\n",
    "    halfsupport = round(3*sigma)   \n",
    "#     halfsupport was 10, for default sigma.  We need a halfsupport of about\n",
    "#     2*sigma for a single Gaussian.  Here we have three, one at -sigma, one at\n",
    "#     sigma, so we should need a halfsupport of about 3*sigma.\n",
    "\n",
    "\n",
    "    sigy = sigma\n",
    "    sigx = sigma # Was sigx = 3*sigma.\n",
    "\n",
    "    gx = RRgaussfilter1D(halfsupport, sigx)\n",
    "    gy = RRgaussfilter1D(halfsupport, sigy, sigma)\n",
    "    Ga = conv2(gx, gy.T)\n",
    "    Ga = Ga/sum(sum(Ga))\n",
    "    gy = RRgaussfilter1D(halfsupport, sigy)\n",
    "    Gb = conv2(gx, gy.T)\n",
    "    Gb = Gb/sum(sum(Gb))\n",
    "    gy = RRgaussfilter1D(halfsupport, sigy, -sigma)\n",
    "    Gc = conv2(gx, gy.T)\n",
    "    Gc = Gc/sum(sum(Gc))\n",
    "    H = -Ga+2*Gb-Gc\n",
    "    V = H.T\n",
    "\n",
    "    GGa = imrotate(Ga, 45, 'bicubic', 'crop')\n",
    "    GGa = GGa/sum(sum(GGa))\n",
    "    GGb = imrotate(Gb, 45, 'bicubic', 'crop')\n",
    "    GGb = GGb/sum(sum(GGb))\n",
    "    GGc = imrotate(Gc, 45, 'bicubic', 'crop')\n",
    "    GGc = GGc/sum(sum(GGc))\n",
    "    R = -GGa+2*GGb-GGc\n",
    "    GGa = imrotate(Ga, -45, 'bicubic', 'crop')\n",
    "    GGa = GGa/sum(sum(GGa))\n",
    "    GGb = imrotate(Gb, -45, 'bicubic', 'crop')\n",
    "    GGb = GGb/sum(sum(GGb))\n",
    "    GGc = imrotate(Gc, -45, 'bicubic', 'crop')\n",
    "    GGc = GGc/sum(sum(GGc))\n",
    "    L = -GGa+2*GGb-GGc\n",
    "\n",
    "    hout = filt2(H,pyr)\n",
    "    vout = filt2(V,pyr)\n",
    "    lout = filt2(L,pyr)\n",
    "    rout = filt2(R,pyr)\n",
    "\n",
    "    hvdd = hout, vout, lout, rout\n",
    "\n",
    "    return hvdd "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "57fe96e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def RROrientationOppEnergy(L_pyr, numlevels):\n",
    "    \"\"\"\n",
    "    OPP_ENERGY    This runs the oriented opponent energy calculation that\n",
    "    serves as the first stages in Bergen & Landy's (1990)\n",
    "    texture segmentor, except it uses DOOG filters (which actually\n",
    "    don't work as well, but at least we can more easily control the\n",
    "    scale).\n",
    "    \"\"\"\n",
    "    \n",
    "    hvdd = [0] * numlevels\n",
    "    hv = [0] * numlevels\n",
    "    dd = [0] * numlevels\n",
    "    out = [0] * numlevels\n",
    "    total = [0] * numlevels\n",
    "    \n",
    "    noise = 1.0    # Was 1.5\n",
    "    filterScale = 16/14*1.75\n",
    "    poolScale = 1.75\n",
    "#     These probably seem like arbitrary numbers, but it's just trying to get\n",
    "#     three very different feature extraction methods to operate at basically\n",
    "#     the same scales.\n",
    "\n",
    "\n",
    "    for scale in range(0, numlevels):\n",
    "#         Check this is the right order for Landy/Bergen. RRR\n",
    "        hvdd[scale] = orient_filtnew(L_pyr[(scale,0)],filterScale) \n",
    "#         filt with 4 oriented filters 0, 45, 90, 135.  Was sigma = 16/14, orient_filtnew,\n",
    "#         then 16/14*1.75 to match contrast and other scales.\n",
    "#         Eventually make this sigma a variable that's passed to this routine.\n",
    "#         hvdd[scale] is the 4 output images concatenated together, \n",
    "#         in the order horizontal, vertical, up-left, and down-right.\n",
    "\n",
    "        hvdd[scale] = [x ** 2 for x in hvdd[scale]]    #local energy\n",
    "        hvdd[scale] = poolnew(hvdd[scale], poolScale) #Pools with a gaussian filter.  Was effectively sigma=1, then 1.75 to match 1.75 above.\n",
    "#         RRR Should look at these results and see if this is the right amount of\n",
    "#         pooling for the new filters.  It was right for the Landy-Bergen\n",
    "#         filters.\n",
    "        hv[scale] = HV(hvdd[scale]) # get the difference image between horizontal and vertical: H-V (0-90)\n",
    "        dd[scale] = DD(hvdd[scale]) # get the difference image between right and left: R-L (45-135)\n",
    "#         Normalize by the total response at this scale, assuming the total\n",
    "#         response is high enough.  If it's too low, we'll never see this\n",
    "#         orientation.  I'm not sure what to do here -- set it to zeros and\n",
    "#         it's like that's the orientation.  Maybe output the total response\n",
    "#         and decide what to do later.  RRR\n",
    "        total[scale] = sumorients(hvdd[scale]) + noise # add noise based upon sumorients at visibility threshold\n",
    "        hv[scale] = hv[scale]/total[scale] # normalize the hv and dd image\n",
    "        dd[scale] = dd[scale]/total[scale]\n",
    "        out[scale] = hv[scale], dd[scale] # out is the 2 output images concatenated together, in the order of hv, dd\n",
    "\n",
    "\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "465d3ee1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def computeOrientationClutter(L_pyr):\n",
    "    \"\"\"\n",
    "    computes the orientation clutter maps. Returns:\n",
    "    clutter_levels, a cell structure, containing the orientation clutter at a \n",
    "    number of scales specified by numlevels;  -- cell(numlevels,1) --, the n'th \n",
    "    level of which can be accessed using clutter_levels{n}{1}\n",
    " \n",
    "    input:\n",
    "        L_pyr\n",
    "        the Gaussian pyramid of L (from CIELab color space)\n",
    "        the Gaussian pyramid is computed by alternately blurring and subsampling the L channels\n",
    "        \n",
    "    Orientation clutter is computed as the \"volume\" of an orientation distribution\n",
    "    ellipsoid, which is the determinant of covariance matrix. Treats cos(2 theta)\n",
    "    and sin(2 theta) (computed from OrientedOppEnergy) as a two-vector, and gets\n",
    "    The covariance of this two-vector.  The covariance \n",
    "    matrix can be computed efficiently through linear filtering. More \n",
    "    specifically, cov(X,Y) = E(XY)-E(X)E(Y), where E (expectation value) \n",
    "    can be approximated by filtering with a Gaussian window. \n",
    "    poolScale is set to 7/2.\n",
    "\n",
    "    Reference (though there is no orientation clutter in this reference):\n",
    "    Ruth Rosenholtz, Yuanzhen Li, Jonathan Mansfield, and Zhenlan Jin. \n",
    "    Feature Congestion: A Measure of Display Clutter. CHI '05: Proc. of the SIGCHI conference \n",
    "    on Human factors in computing systems. May 2005. 761-770.  \n",
    "\n",
    "    Based upon RRcomputeOrientationSaliency\n",
    "    Ruth Rosenholtz, May 2006\n",
    "\n",
    "    This currently seems far too dependent on luminance contrast.  Check into\n",
    "    why this is so -- I thought we were normalizing by local contrast.\n",
    "    \n",
    "    \"\"\"\n",
    "\n",
    "    noise = 0.001  # Was eps, but that gave too much orientation noise in the saliency maps.  Then changed to 0.000001\n",
    "    poolScale = 7/2\n",
    "\n",
    "    numlevels = len(L_pyr);\n",
    "    Dc = [0] * numlevels  # mean \"cos 2 theta\" at distractor scale\n",
    "    Ds = [0] * numlevels  # mean \"sin 2 theta\" at distractor scale\n",
    "\n",
    "#     Get approximations to cos(2theta) and sin(2theta) from oriented opponent\n",
    "#     energy, at each of the numlevels of the pyramid\n",
    "    angles = RROrientationOppEnergy(L_pyr, numlevels)\n",
    "\n",
    "#     Compute the two-vector [meancos, meansin] at each scale, as well as the\n",
    "#     things we need to compute the mean and covariance of this two-vector at\n",
    "#     the larger, distractor scale.\n",
    "\n",
    "    bigG = RRgaussfilter1D(round(8*poolScale), 4*poolScale)\n",
    "    maxbigG = max(bigG) ** 2\n",
    "\n",
    "    \n",
    "    covMx = {}\n",
    "    clutter_levels = [0] * numlevels\n",
    "\n",
    "    for i in range(0,numlevels):\n",
    "        cmx = angles[i][0]\n",
    "        smx = angles[i][1]\n",
    "\n",
    "#         Pool to get means at distractor scale. In pooling, don't pool over the target\n",
    "#         region (implement this by pooling with a big Gaussian, then\n",
    "#         subtracting the pooling over the target region computed above.  Note,\n",
    "#         however, that we first need to scale the target region pooling so\n",
    "#         that its peak is the same height as this much broader Gaussian used\n",
    "#         to pool over the distractor region.\n",
    "                  \n",
    "        Dc[i] = RRoverlapconv(bigG, cmx)\n",
    "        Dc[i] = RRoverlapconv(bigG.T, Dc[i])\n",
    "        Ds[i] = RRoverlapconv(bigG, smx)\n",
    "        Ds[i] = RRoverlapconv(bigG.T, Ds[i])\n",
    "\n",
    "#         Covariance matrix elements.  Compare with computations in\n",
    "#         RRStatisticalSaliency.  I tried to match computeColorClutter, but I\n",
    "#         don't remember the meaning of some of the terms I removed.  XXX\n",
    "        covMx[(i,0,0)] = RRoverlapconv(bigG, cmx ** 2)\n",
    "        covMx[(i,0,0)] = RRoverlapconv(bigG.T, covMx[(i,0,0)]) - Dc[i] ** 2 + noise\n",
    "        covMx[(i,0,1)] = RRoverlapconv(bigG, cmx * smx)\n",
    "        covMx[(i,0,1)] = RRoverlapconv(bigG.T, covMx[(i,0,1)]) - Dc[i] * Ds[i]\n",
    "        covMx[(i,1,1)] = RRoverlapconv(bigG, smx ** 2)\n",
    "        covMx[(i,1,1)] = RRoverlapconv(bigG.T, covMx[(i,1,1)]) - Ds[i] ** 2 + noise\n",
    "\n",
    "#         Get determinant of covariance matrix, which is the volume of the\n",
    "#         covariance ellipse\n",
    "        detIm = covMx[(i,0,0)] * covMx[(i,1,1)] - covMx[(i,0,1)] ** 2\n",
    "#         Take the square root considering variance is squared, and the square\n",
    "#         root again, since this is the area and the contrast measure is a \"length\"\n",
    "        clutter_levels[i] = detIm ** (1/4)\n",
    "\n",
    "        \n",
    "    return clutter_levels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "f61281b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def orientationClutter(inputImage, numlevels, pix=1):\n",
    "    \n",
    "    pool_sigma = 7/2\n",
    "\n",
    "\n",
    "    if isinstance(inputImage, list):\n",
    "        L_pyr = inputImage[0]\n",
    "        \n",
    "    else:\n",
    "        if isinstance(inputImage, str):\n",
    "            im = cv2.imread(inputImage)\n",
    "            if im is None:\n",
    "                raise ValueError('Unable to open %s image file.')\n",
    "\n",
    "        elif isinstance(inputImage, np.ndarray):\n",
    "            im = inputImage\n",
    "             \n",
    "        m, n, d = im.shape\n",
    "        if d == 3:\n",
    "            Lab = cv2.cvtColor(im, cv2.COLOR_RGB2LAB)\n",
    "            L = Lab[:,:,0]\n",
    "        else:\n",
    "            raise ValueError('should be run on RGB color images.  Input image appears to be grayscale.\\n')\n",
    "\n",
    "    \n",
    "#         Get Gaussian pyramid for the luminance channel\n",
    "        pyr = pt.pyramids.GaussianPyramid(Lab[:,:,0], height=numlevels)\n",
    "        L_pyr = pyr.pyr_coeffs\n",
    "\n",
    "#     Compute clutter\n",
    "    clutter_levels = computeOrientationClutter(L_pyr)\n",
    "\n",
    "    \n",
    "    kernel_1d = np.array([[0.05, 0.25, 0.4, 0.25, 0.05]])\n",
    "    kernel_2d = conv2(kernel_1d, kernel_1d.T)\n",
    "    \n",
    "    clutter_map = clutter_levels[0]\n",
    "    for scale in range(1,numlevels):\n",
    "        clutter_here = clutter_levels[scale]\n",
    "        \n",
    "        for kk in range(scale, 0, -1):\n",
    "            clutter_here = pt.upConv(image=clutter_here, filt=kernel_2d, edge_type='reflect1', step=[2,2], start=[0,0])\n",
    "    \n",
    "        common_sz = min(clutter_map.shape[0], clutter_here.shape[0]), min(clutter_map.shape[1], clutter_here.shape[1])\n",
    "        for i in range(0, common_sz[0]):\n",
    "            for j in range(0, common_sz[1]):\n",
    "                 clutter_map[i][j] = max(clutter_map[i][j], clutter_here[i][j])\n",
    "\n",
    "    \n",
    "    \n",
    "    return clutter_levels, clutter_map"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c39bd795",
   "metadata": {},
   "source": [
    "## CLUTTER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "8420a942",
   "metadata": {},
   "outputs": [],
   "source": [
    "def computeClutter(inputImage, numlevels=3, contrast_filt_sigma=1, contrast_pool_sigma=None, color_pool_sigma=3, contrast_pix=0, color_pix=0, orient_pix=0):\n",
    "    \n",
    "    if contrast_pool_sigma is None:\n",
    "        contrast_pool_sigma = 3 * contrast_filt_sigma\n",
    "\n",
    "    orient_pool_sigma = 7/2\n",
    "\n",
    "    if isinstance(inputImage, str):\n",
    "        im = cv2.imread(inputImage)\n",
    "        if im is None:\n",
    "            print('Unable to open %s image file.') #TODO: add logger\n",
    "            return 0\n",
    "        else:\n",
    "            m, n, d = im.shape\n",
    "            if d == 3:\n",
    "                Lab = cv2.cvtColor(im, cv2.COLOR_RGB2LAB)\n",
    "                RRLab = [0, 0, 0]\n",
    "            else:\n",
    "                print('should be run on RGB color images.  Input image appears to be grayscale.\\n')\n",
    "                return 0\n",
    "  \n",
    "    else:\n",
    "        pass #TODO \n",
    "\n",
    "    pyr = pt.pyramids.GaussianPyramid(Lab[:,:,0], height=numlevels)\n",
    "    RRLab[0] = pyr.pyr_coeffs\n",
    "\n",
    "    pyr = pt.pyramids.GaussianPyramid(Lab[:,:,1], height=numlevels)\n",
    "    RRLab[1] = pyr.pyr_coeffs\n",
    "\n",
    "    pyr = pt.pyramids.GaussianPyramid(Lab[:,:,0], height=numlevels)\n",
    "    RRLab[2] = pyr.pyr_coeffs\n",
    "        \n",
    "    \n",
    "#     # compute the color clutter\n",
    "    color_clutter_levels, color_clutter_map = colorClutter(RRLab, numlevels, color_pool_sigma, color_pix)\n",
    "#     # compute the contrast clutter\n",
    "    contrast_clutter_levels, contrast_clutter_map = contrastClutter(RRLab, numlevels, contrast_filt_sigma, contrast_pool_sigma, contrast_pix)\n",
    "#     #compute the orientation clutter\n",
    "    orient_clutter_levels, orientation_clutter_map = orientationClutter(RRLab, numlevels, orient_pix)\n",
    "\n",
    "#     # output them in cell structures\n",
    "    color_clutter = [color_clutter_levels, color_clutter_map]\n",
    "    contrast_clutter = [contrast_clutter_levels, contrast_clutter_map]\n",
    "    orientation_clutter = [orient_clutter_levels, orientation_clutter_map]\n",
    "\n",
    "\n",
    "    return color_clutter, contrast_clutter, orientation_clutter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "0b2cd598",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getClutter_FC(filename, p=1):\n",
    "    color_clutter, contrast_clutter, orient_clutter = computeClutter(filename, 3, 1, 3, 3, 0, 0, 0)\n",
    "    clutter_map_fc = color_clutter[1] / 0.2088 + contrast_clutter[1] / 0.0660 + orient_clutter[1] / 0.0269\n",
    "    clutter_scalar_fc = np.mean(clutter_map_fc ** p) ** (1 / p) #element wise\n",
    "    return clutter_scalar_fc, clutter_map_fc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "3842d8f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test\n",
    "\n",
    "color_clutter, contrast_clutter, orientation_clutter = computeClutter('test.jpg', 3, 1, 3, 3, 0, 0, 0)\n",
    "clutter_scalar_fc, clutter_map_fc = getClutter_FC('test.jpg')\n",
    "\n",
    "img1 = Image.fromarray(color_clutter[1]/0.01) #0.01 for test: more brightness/\n",
    "img2 = Image.fromarray(contrast_clutter[1]/0.01) #0.01 for test: more brightness\n",
    "img3 = Image.fromarray(orientation_clutter[1]/0.01) #0.01 for test: more brightness\n",
    "\n",
    "img4 = Image.fromarray(clutter_map_fc) #0.01 for test: more brightness\n",
    "\n",
    "img1.show()\n",
    "img2.show()\n",
    "img3.show()\n",
    "img4.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
